use crate::bus::types::Bus;
use crate::config::config::AppCfg;
use crate::core::types::{
    Actor, Execution, MarketDataRequest, MarketDataSnap, Order, PolyMarketEvent, Portfolio, RawNews,
};
use crate::llm::LlmClient;
use crate::persistence::database::Database;
use crate::strategy::analyst::MarketAnalyst;
use crate::strategy::event_features::{EventFeatureExtractor, FeatureDictionaries};
use crate::strategy::exact_duplicate_detector::{
    ExactDuplicateDetector, ExactDuplicateDetectorConfig,
};
use crate::strategy::hard_filters::HardFilterer;
use crate::strategy::kelly::KellySizer;
use crate::strategy::market_index::MarketIndex;
use crate::strategy::sim_hash_cache::{SimHashCache, SimHashCacheConfig};
use crate::strategy::tokenization::{TokenizationConfig, TokenizedNews};
use crate::strategy::types::*;
use anyhow::Result;
use chrono::Utc;
use rust_decimal::Decimal;
use rust_decimal::prelude::*;
use std::collections::HashMap;
use tokio_util::sync::CancellationToken;
use tracing::{error, info, warn};

pub struct StrategyActor {
    pub bus: Bus,
    pub shutdown: CancellationToken,
    pub detector: ExactDuplicateDetector,
    pub sim_hash_cache: SimHashCache,
    pub event_feature_extractor: EventFeatureExtractor,
    pub market_index: MarketIndex,
    pub hard_filterer: HardFilterer,
    pub kelly_sizer: KellySizer,
    pub market_data_cache: HashMap<String, MarketDataSnap>,
    pub analyst: MarketAnalyst,
    pub db: Database,
    pub portfolio: Portfolio,
    pub status: crate::core::types::SystemStatus,
    pub top_candidates: usize,
    pub tokenization_config: TokenizationConfig,
    pub market_state_cache: HashMap<String, u64>,
    pub max_position_drawdown_pct: Decimal,
}

impl StrategyActor {
    pub fn new(bus: Bus, shutdown: CancellationToken, cfg: &AppCfg, db: Database) -> StrategyActor {
        Self {
            bus,
            shutdown,
            detector: ExactDuplicateDetector::new(ExactDuplicateDetectorConfig::default()),
            sim_hash_cache: SimHashCache::new(SimHashCacheConfig::default()),
            event_feature_extractor: EventFeatureExtractor::new(
                FeatureDictionaries::default_minimal(),
            ),
            market_index: MarketIndex::new().expect("Failed to initialize MarketIndex"),
            hard_filterer: HardFilterer::new(),
            kelly_sizer: KellySizer::default(),
            market_data_cache: HashMap::new(),
            analyst: MarketAnalyst::new(
                LlmClient::new(cfg.llm.clone()),
                db.clone(),
                cfg.strategy.top_candidates,
            ),
            db,
            portfolio: Portfolio {
                positions: HashMap::new(),
                cash: Decimal::ZERO, // Init to 0, ExecutionActor will update via BalanceUpdate
                total_equity: Decimal::ZERO,
            },
            status: crate::core::types::SystemStatus::Active,
            top_candidates: cfg.strategy.top_candidates,
            tokenization_config: TokenizationConfig::default(),
            market_state_cache: HashMap::new(),
            max_position_drawdown_pct: Decimal::from_f64(cfg.strategy.max_position_drawdown_pct)
                .unwrap_or(Decimal::new(2, 1)), // 0.2 default if fail
        }
    }

    async fn decide_from_tick(&mut self, snap: &MarketDataSnap) -> Option<Order> {
        self.market_data_cache
            .insert(snap.market_id.clone(), snap.clone());

        // 1. Update Portfolio Valuations (Mark-to-Market)
        let mut liquidation_order: Option<Order> = None;

        if let Some(tokens) = &snap.tokens {
            for token in tokens {
                if let Some(pos) = self.portfolio.positions.get_mut(&token.token_id) {
                    // Update PnL
                    pos.current_price = token.price;
                    pos.unrealized_pnl = (token.price - pos.avg_entry_price) * pos.quantity;
                    pos.last_updated_ts = Utc::now().timestamp_millis();

                    // 2. Check Per-Position Drawdown (Stop Loss)
                    if pos.quantity > Decimal::ZERO && pos.avg_entry_price > Decimal::ZERO {
                        let pct_change = (token.price - pos.avg_entry_price) / pos.avg_entry_price;
                        // e.g. -0.25 < -0.20
                        if pct_change < -self.max_position_drawdown_pct {
                            warn!(
                                "STOP LOSS TRIGGERED for {}: Drop {:.2}% exceeds limit {:.2}%. Liquidating.",
                                token.token_id,
                                pct_change * Decimal::from(100),
                                self.max_position_drawdown_pct * Decimal::from(100)
                            );

                            // Trigger Liquidation
                            if liquidation_order.is_none() {
                                liquidation_order = Some(Order {
                                    client_order_id: format!(
                                        "liq-{}",
                                        Utc::now().timestamp_micros()
                                    ),
                                    market_id: pos.market_id.clone(),
                                    token_id: Some(pos.token_id.clone()),
                                    side: crate::core::types::Side::Sell,
                                    price: token.price,
                                    size: pos.quantity,
                                });
                            }
                        }
                    }
                }
            }
        }

        // 3. Calculate Global NLV
        let mut total_pos_value = Decimal::ZERO;
        for pos in self.portfolio.positions.values() {
            total_pos_value += pos.quantity * pos.current_price;
        }
        self.portfolio.total_equity = self.portfolio.cash + total_pos_value;

        // Metrics
        metrics::gauge!("strategy_portfolio_cash").set(self.portfolio.cash.to_f64().unwrap_or(0.0));
        metrics::gauge!("strategy_portfolio_nlv")
            .set(self.portfolio.total_equity.to_f64().unwrap_or(0.0));

        // 4. Publish Portfolio Update
        let update = crate::core::types::PortfolioUpdate {
            cash: self.portfolio.cash,
            total_equity: self.portfolio.total_equity,
            timestamp: Utc::now().timestamp_millis(),
        };

        if let Err(e) = self.bus.portfolio_update.publish(update).await {
            error!("Failed to publish portfolio update: {:#}", e);
        }

        liquidation_order
    }

    // ============================
    // Pipeline: News / Events
    // ============================

    /// Core pipeline for a fresh news item:
    /// 1) Check for halt
    /// 2) Exact Dedup based on raw news event
    /// 2) Normalize + tokenize
    /// 3) Semantic dedup
    /// 4) Entity & date extraction
    /// 5) Candidate generation using lexical and semantic lookup
    /// 6) Hard filters
    /// 7) llm scoring
    /// 8) Kelly sizing + risk caps
    /// 9) Build orders
    #[tracing::instrument(skip(self, raw_news), fields(title = %raw_news.title))]
    async fn handle_news_event(&mut self, raw_news: &RawNews) -> Vec<Order> {
        let start = std::time::Instant::now();
        let order = Vec::new();

        // 1. Check for Halt
        if let crate::core::types::SystemStatus::Halted(reason) = &self.status {
            warn!("Skipping news processing due to HALT: {}", reason);
            return order;
        }

        metrics::counter!("strategy_news_processed_total").increment(1);

        // 2. Cheap exact dedup to eliminate trivial duplicates
        if self.detector.is_duplicate(raw_news) {
            // Count exact duplicates
            metrics::counter!("strategy_duplicates_total", "type" => "exact").increment(1);
            return order; // Return empty if dup
        }

        // Persist Event (fire and forget / log error)
        let event_db_id = match self.db.save_event(raw_news).await {
            Ok(id) => Some(id),
            Err(e) => {
                error!("Failed to save event to DB: {:#}", e);
                None
            }
        };

        info!("New event {:?} â€” continue pipeline.", event_db_id);

        // 2. Tokenize
        let tokenized_news = TokenizedNews::from_raw(raw_news.clone(), &self.tokenization_config);

        // 3. Semantic dedup (SimHash) to eliminate rewritten versions
        let h = self.sim_hash_cache.sim_hash(&tokenized_news.tokens);
        if self.sim_hash_cache.is_near_duplicate(h) {
            info!("Near-duplicate news skipped (SimHash).");
            metrics::counter!("strategy_duplicates_total", "type" => "simhash").increment(1);
            return order;
        }
        self.sim_hash_cache.insert(h);

        // 4. lexical and semantic using hard coded rules => semantic is generated from lexical
        let now = Utc::now();
        let feat = self.event_feature_extractor.extract(&tokenized_news, now); // Lexical layer (layers, numbers, time window)

        // 5. Candidate generation with Hybrid Search (BM25 + Semantic)
        let raw_candidates =
            self.retrieve_candidates(tokenized_news.tokens.as_slice(), &raw_news.title);

        metrics::counter!("strategy_candidates_found_total").increment(raw_candidates.len() as u64);

        // Log retrievals for debugging
        if let Some(eid) = event_db_id {
            for cand in &raw_candidates {
                if let Err(e) = self.db.save_candidate_market(eid, &cand.market_id).await {
                    error!("Failed to save candidate market: {}", e);
                }
            }
        }

        if raw_candidates.is_empty() {
            warn!(
                "No candidates found for news: ({}). Skipping.",
                raw_news.title
            );
            return order;
        }

        // 6. Hard filters
        let entities = &feat.entities;
        let time_window = &feat.time_window;
        let initial_count = raw_candidates.len();
        let filtered_candidates = self
            .hard_filterer
            .apply(raw_candidates, entities, time_window);

        let filtered_count = initial_count - filtered_candidates.len();
        metrics::counter!("strategy_candidates_filtered_total").increment(filtered_count as u64);

        // Take top N candidates for ensure_market_data optimization
        let top_candidates_for_data = filtered_candidates
            .iter()
            .take(self.top_candidates)
            .map(|c| c.clone())
            .collect::<Vec<_>>();

        info!(
            "Top {} candidates after filtering: {:?}",
            top_candidates_for_data.len(),
            top_candidates_for_data
                .iter()
                .map(|c| &c.market_id)
                .collect::<Vec<_>>()
        );

        // Ensure we have market data (Price + Question) for these candidates
        // Note: We need to convert back to RawCandidate for ensure_market_data or just pass cloned vec
        info!(
            "Ensuring market data for: {:?}",
            top_candidates_for_data
                .iter()
                .map(|c| &c.market_id)
                .collect::<Vec<_>>()
        );
        self.ensure_market_data(&top_candidates_for_data).await;

        // 7. Analyst (LLM Scoring)
        let analyst_start = std::time::Instant::now();
        // Pass the candidates to analyst. Analyst will also limit to top_candidates internally,
        // but since we already filtered for data fetching efficiency, we pass what we have.
        // Analyst expects Vec<RawCandidate>.
        let edged_candidates = self
            .analyst
            .analyze_candidates(
                raw_news,
                filtered_candidates, // Pass all filtered, Analyst handles top_N logic
                &self.market_data_cache,
                event_db_id,
            )
            .await;
        metrics::histogram!("strategy_analyst_duration_seconds")
            .record(analyst_start.elapsed().as_secs_f64());

        // 8. Kelly Sizing
        let sized_decisions = self.kelly_sizer.size_positions(edged_candidates);
        metrics::counter!("strategy_decisions_sized_total").increment(sized_decisions.len() as u64);

        // Persist Decisions
        for decision in &sized_decisions {
            if let Err(e) = self.db.save_decision(event_db_id, decision).await {
                error!("Failed to save decision: {:#}", e);
            }
        }

        // 9. Build Orders
        let orders = self
            .build_orders_from_sized_decisions(&sized_decisions, event_db_id)
            .await;

        metrics::counter!("strategy_orders_generated_total").increment(orders.len() as u64);
        metrics::histogram!("strategy_processing_duration_seconds")
            .record(start.elapsed().as_secs_f64());
        orders
    }

    fn retrieve_candidates(&mut self, tokens: &[String], raw_text: &str) -> Vec<RawCandidate> {
        let mut candidates = HashMap::new();

        // 1. BM25 Search
        if let Ok(results) = self.market_index.search(tokens, 50) {
            for c in results {
                candidates.insert(c.market_id.clone(), c);
            }
        } else {
            warn!("BM25 search failed");
        }

        // 2. Semantic Search
        if let Ok(results) = self.market_index.search_semantic(raw_text, 50) {
            for c in results {
                // If exists, we could merge scores or keep the one with higher score.
                // For now, just insert if not present (union).
                // Or maybe we want to boost score if found in both?
                // Let's just add unique ones.
                candidates.entry(c.market_id.clone()).or_insert(c);
            }
        } else {
            warn!("Semantic search failed");
        }

        candidates.into_values().collect()
    }

    async fn ensure_market_data(&mut self, candidates: &[RawCandidate]) {
        let missing_ids: Vec<String> = candidates
            .iter()
            .map(|c| c.market_id.clone())
            .filter(|id| !self.market_data_cache.contains_key(id))
            .collect();

        if missing_ids.is_empty() {
            return;
        }

        // Subscribe to market data updates *before* sending requests to avoid races
        let mut rx = self.bus.market_data.subscribe();

        for id in &missing_ids {
            let req = MarketDataRequest {
                market_id: id.clone(),
            };
            if let Err(e) = self.bus.market_data_request.publish(req).await {
                error!("Failed to publish market data request: {:#}", e);
            }
        }

        // Wait for data with a timeout
        let timeout = tokio::time::sleep(std::time::Duration::from_millis(2000));
        tokio::pin!(timeout);

        loop {
            tokio::select! {
                _ = &mut timeout => {
                    warn!("Timeout waiting for market data");
                    break;
                }
                res = rx.recv() => {
                    match res {
                        Ok(snap) => {
                            self.market_data_cache.insert(snap.market_id.clone(), (*snap).clone());
                            if missing_ids.iter().all(|id| self.market_data_cache.contains_key(id)) {
                                break;
                            }
                        }
                        Err(_) => break,
                    }
                }
            }
        }
    }

    async fn build_orders_from_sized_decisions(
        &self,
        sized: &[SizedDecision],
        event_id: Option<i64>,
    ) -> Vec<Order> {
        let mut orders = Vec::new();
        // Use total equity as bankroll for sizing
        let bankroll = self.portfolio.total_equity;

        for decision in sized {
            if decision.size_fraction <= Decimal::ZERO {
                continue;
            }

            // Calculate quantity based on bankroll and price
            // size_fraction is the fraction of bankroll to risk/invest
            // quantity = (bankroll * size_fraction) / price
            let price = decision.candidate.market_price;
            if price <= Decimal::ZERO {
                continue;
            }

            let quantity = (bankroll * decision.size_fraction) / price;

            // Generate a simple client order ID
            let client_order_id = format!(
                "{}-{}",
                decision.candidate.candidate.market_id,
                Utc::now().timestamp_micros()
            );

            // Snapshot ID for Audit
            let mut snap_id = None;

            // Resolve token_id
            let mut token_id = None;
            if let Some(snap) = self
                .market_data_cache
                .get(&decision.candidate.candidate.market_id)
            {
                // Persist Snapshot for Audit (Event Link)
                match self.db.save_market_data_snap(snap, event_id).await {
                    Ok(id) => snap_id = Some(id),
                    Err(e) => error!("Failed to save audit snapshot: {:#}", e),
                }

                if let Some(tokens) = &snap.tokens {
                    let target_outcome = match &decision.side {
                        TradeSide::Buy(outcome) => outcome,
                    };

                    // Case-insensitive match + Robust check (e.g. "Yes" vs "True")
                    // For now, strict case-insensitive match on the outcome label.
                    if let Some(t) = tokens
                        .iter()
                        .find(|t| t.outcome.eq_ignore_ascii_case(target_outcome))
                    {
                        token_id = Some(t.token_id.clone());
                    } else {
                        // Fallback: Log available outcomes to help debug multi-choice issues
                        let available: Vec<String> =
                            tokens.iter().map(|t| t.outcome.clone()).collect();
                        warn!(
                            "Token ID not found for outcome '{}' in market {}. Available: {:?}",
                            target_outcome, decision.candidate.candidate.market_id, available
                        );
                    }
                }
            }

            let order = Order {
                client_order_id,
                market_id: decision.candidate.candidate.market_id.clone(),
                token_id,
                side: crate::core::types::Side::Buy, // Always Buy side for the specific token
                price,
                size: quantity,
            };

            // Persist Order
            if let Err(e) = self.db.save_order(&order, snap_id).await {
                error!("Failed to save order: {:#}", e);
            }

            orders.push(order);
        }
        orders
    }

    async fn decide_from_news(&mut self, news: &RawNews) -> Option<Order> {
        // Full matching + decision pipeline for generic news.
        self.handle_news_event(news).await.into_iter().next()
    }

    async fn decide_from_poly_event(&mut self, event: &PolyMarketEvent) -> Option<Order> {
        if let Some(markets) = &event.markets {
            for market in markets {
                // Compute Hash
                let mut hasher = std::collections::hash_map::DefaultHasher::new();
                std::hash::Hash::hash(&market, &mut hasher);
                let new_hash = std::hash::Hasher::finish(&hasher);

                // Check Cache
                if let Some(cached_hash) = self.market_state_cache.get(&market.id) {
                    if *cached_hash == new_hash {
                        // Unchanged, skip
                        continue;
                    }
                }

                // Persist Market
                if let Err(e) = self.db.save_market(&market).await {
                    error!("Failed to save market {}: {:#}", market.id, e);
                } else {
                    // Update Cache on success
                    self.market_state_cache.insert(market.id.clone(), new_hash);
                }

                if market.closed {
                    // Remove from index if closed
                    if self.market_index.contains(&market.id) {
                        if let Err(e) = self.market_index.delete_market(&market.id) {
                            error!("Failed to delete closed market {}: {}", market.id, e);
                        } else {
                            info!("MarketIndex: Removed closed market {}", market.id);
                        }
                    }
                } else {
                    let question = market
                        .question
                        .as_deref()
                        .or(event.title.as_deref())
                        .unwrap_or("");
                    let description = market
                        .description
                        .as_deref()
                        .or(event.description.as_deref())
                        .unwrap_or("");

                    if !question.is_empty() {
                        if let Err(e) = self.market_index.add_market(
                            &market.id,
                            question,
                            description,
                            "",
                            None,
                        ) {
                            error!("Failed to index market {}: {}", market.id, e);
                        } else {
                            info!("MarketIndex: Added/Updated market {:#}", market.id);
                        }
                    }
                }
            }
        }
        None
    }

    async fn decide_from_executions(&mut self, execution: &Execution) -> Option<Order> {
        info!("StrategyActor received execution: {:?}", execution);

        // 1. Persist Execution
        if let Err(e) = self.db.save_execution(execution).await {
            error!("Failed to save execution: {:#}", e);
        }

        // 2. Update Portfolio
        // We need a token_id to uniquely identify the position.
        // The Execution may not have it if it comes from exchange drop copy generically,
        // but our Execution struct doesn't have it either (it has market_id).
        // However, standard Polymarket positions are on Token IDs (ERC1155).
        // Since we don't have token_id in Execution msg, we have to look it up or assume logic.
        // PROVISIONAL: We will assume we can derive or find it.
        // For now, let's try to match with an open order if we had one?
        // Or simpler: Use "MarketID-Side" as a composite key if we only hold one token per side per market?
        // Actually, we stored `token_id` in `Order` table. We could query DB for the order by `client_order_id` to get `token_id`.
        // This causes a DB read per execution, but is safe.

        // For this step, I will leave a TODO and use market_id as fallback valid token_id.
        let token_id = execution
            .token_id
            .clone()
            .unwrap_or(execution.market_id.clone());

        if let Some(updated_pos) = self.portfolio.update_from_execution(execution, &token_id) {
            info!("Updated position for {}: {:?}", token_id, updated_pos);

            // 3. Persist Position
            if let Err(e) = self.db.upsert_position(&updated_pos).await {
                error!("Failed to upsert position: {:#}", e);
            }
        }

        None
    }

    fn reconcile_positions(&mut self, snap: &crate::core::types::PositionSnapshot) {
        info!(
            "Reconciling portfolio with {} external positions",
            snap.positions.len()
        );

        // 1. Mark all current positions as potentially stale (optional, or just clear and rebuild?)
        // Clearing and rebuilding is safer to remove "zombie" positions (internal yes, external no).
        // However, we lose "avg_entry_price" if the external API doesn't provide it nicely.
        // Polymarket API provides average entry price usually. The struct Position has it.
        // Assuming the snapshot Position has correct data.

        // Let's iterate and overwrite.
        // Also need to identify positions present in internal but NOT in snapshot (closed manually?).

        let mut present_token_ids = std::collections::HashSet::new();

        for ext_pos in &snap.positions {
            present_token_ids.insert(ext_pos.token_id.clone());

            // Check drift
            if let Some(int_pos) = self.portfolio.positions.get(&ext_pos.token_id) {
                if int_pos.quantity != ext_pos.quantity {
                    warn!(
                        "Position DRIFT for {}: Internal {} vs External {}. Adjusting.",
                        ext_pos.token_id, int_pos.quantity, ext_pos.quantity
                    );
                }
            } else {
                info!(
                    "New external position found during reconciliation: {}",
                    ext_pos.token_id
                );
            }

            // Overwrite
            self.portfolio
                .positions
                .insert(ext_pos.token_id.clone(), ext_pos.clone());
        }

        // Remove zombies
        let internal_ids: Vec<String> = self.portfolio.positions.keys().cloned().collect();
        for id in internal_ids {
            if !present_token_ids.contains(&id) {
                warn!("Removing ZOMBIE position {} (not on exchange)", id);
                self.portfolio.positions.remove(&id);
            }
        }
    }
}

#[async_trait::async_trait]
impl Actor for StrategyActor {
    async fn run(mut self) -> Result<()> {
        info!("StrategyActor started");

        // Load positions from DB
        match self.db.load_positions().await {
            Ok(positions) => {
                info!("Loaded {} positions from database", positions.len());
                for pos in positions {
                    self.portfolio.positions.insert(pos.token_id.clone(), pos);
                }
            }
            Err(e) => {
                error!("Failed to load positions from database: {:#}", e);
            }
        }

        // Hydrate Duplicate Detector
        match self.db.load_recent_events(10000).await {
            Ok(events) => {
                let count = events.len();
                self.detector.hydrate(events.clone());
                self.sim_hash_cache
                    .hydrate(events, &self.tokenization_config);
                info!(
                    "Hydrated Deduplication Cache & SimHash with {} recent events",
                    count
                );
            }
            Err(e) => {
                error!("Failed to load recent events for deduplication: {:#}", e);
            }
        }

        // Hydrate Market State Cache & Market Index
        match self.db.load_markets().await {
            Ok(markets) => {
                let count = markets.len();
                let mut indexed_count = 0;
                for market in markets {
                    // 1. Hydrate Market State Cache
                    let mut hasher = std::collections::hash_map::DefaultHasher::new();
                    std::hash::Hash::hash(&market, &mut hasher);
                    let new_hash = std::hash::Hasher::finish(&hasher);
                    self.market_state_cache.insert(market.id.clone(), new_hash);

                    // 2. Hydrate Market Index (if active/open)
                    if !market.closed && market.active {
                        let question = market.question.as_deref().unwrap_or("");
                        let description = market.description.as_deref().unwrap_or("");

                        if !question.is_empty() {
                            if let Err(e) = self.market_index.add_market(
                                &market.id,
                                question,
                                description,
                                "",
                                None,
                            ) {
                                error!("Failed to index market {} from DB: {:#}", market.id, e);
                            } else {
                                indexed_count += 1;
                            }
                        }
                    }
                }
                info!("Hydrated market_state_cache with {} markets", count);
                info!("Hydrated MarketIndex with {} active markets", indexed_count);
            }
            Err(e) => {
                error!("Failed to load markets for hydration: {:#}", e);
            }
        }

        // Subscribe to both broadcast streams
        let mut md_rx = self.bus.market_data.subscribe();
        let mut poly_rx = self.bus.polymarket_events.subscribe();
        let mut news_rx = self.bus.raw_news.subscribe();
        let mut executions_rx = self.bus.executions.subscribe();
        let mut balance_rx = self.bus.balance.subscribe();
        let mut status_rx = self.bus.system_status.subscribe();
        let mut snapshot_rx = self.bus.positions_snapshot.subscribe();
        let mut polling_interval = tokio::time::interval(std::time::Duration::from_secs(5));

        loop {
            tokio::select! {
                // Polling Loop for Market Data
                _ = polling_interval.tick() => {
                    // Gather unique market IDs from active positions
                    let mut market_ids = std::collections::HashSet::new();
                    for pos in self.portfolio.positions.values() {
                        if pos.quantity > Decimal::ZERO {
                            market_ids.insert(pos.market_id.clone());
                        }
                    }

                    if !market_ids.is_empty() {
                         metrics::counter!("strategy_market_data_polls_total").increment(1);
                         info!("Polling market data for {} active markets", market_ids.len());
                         for market_id in market_ids {
                             let req = MarketDataRequest { market_id };
                             if let Err(e) = self.bus.market_data_request.publish(req).await {
                                 error!("Failed to publish market data poll request: {:#}", e);
                             }
                         }
                    }
                }

                // Graceful shutdown signal
                _ = self.shutdown.cancelled() => {
                    info!("StrategyActor: shutdown requested");
                    break;
                }

                // System Status
                res = status_rx.recv() => {
                    match res {
                        Ok(status) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "status").increment(1);
                            info!("StrategyActor received system status update: {:?}", status);
                            self.status = (*status).clone();
                            if let crate::core::types::SystemStatus::Halted(reason) = &self.status {
                                warn!("StrategyActor HALTED: {}. Triggering Global Liquidation.", reason);

                                // LIQUIDATE EVERYTHING
                                let mut liquidation_orders = Vec::new();
                                for pos in self.portfolio.positions.values() {
                                    if pos.quantity > Decimal::ZERO {
                                        warn!("Refusing to hold {:?} during Halt. Liquidating.", pos.token_id);
                                        let order = Order {
                                            client_order_id: format!("global-liq-{}", Utc::now().timestamp_micros()),
                                            market_id: pos.market_id.clone(),
                                            token_id: Some(pos.token_id.clone()),
                                            side: crate::core::types::Side::Sell,
                                            price: pos.current_price, // Best effort
                                            size: pos.quantity,
                                        };
                                        liquidation_orders.push(order);
                                    }
                                }

                                for order in liquidation_orders {
                                    if let Err(e) = self.bus.orders.publish(order).await {
                                        error!("Failed to publish liquidation order: {:#}", e);
                                    }
                                }
                            }
                        }
                        Err(e) => {
                             metrics::counter!("strategy_bus_lag_errors_total", "channel" => "status").increment(1);
                             error!("System status stream error: {:#}", e)
                        },
                    }
                }

                // Position Reconciliation
                res = snapshot_rx.recv() => {
                    match res {
                        Ok(snap) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "snapshot").increment(1);
                            self.reconcile_positions(&snap);
                        }
                        Err(e) => {
                             metrics::counter!("strategy_bus_lag_errors_total", "channel" => "snapshot").increment(1);
                             error!("Position snapshot stream error: {:#}", e)
                        },
                    }
                }

                // Market data path
                res = md_rx.recv() => {
                    match res {
                        Ok(snap) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "market_data").increment(1);

                            // Persist Snapshot
                            if let Err(e) = self.db.save_market_data_snap(&snap, None).await {
                                error!("Failed to save market data snap: {:#}", e);
                            }

                            if let Some(order) = self.decide_from_tick(&snap).await {
                                // Publish order to orders topic
                                self.bus.orders.publish(order).await?;
                            }
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
                            metrics::counter!("strategy_bus_lag_errors_total", "channel" => "market_data").increment(1);
                            warn!(lagged = n, "StrategyActor lagged on market_data");
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Closed) => {
                            error!("market_data stream closed; exiting StrategyActor");
                            break;
                        }
                    }
                }

                // News path
                res = news_rx.recv() => {
                    match res {
                        Ok(news) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "news").increment(1);
                            if let Some(order) = self.decide_from_news(&news).await {
                                self.bus.orders.publish(order).await?;
                            }
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
                            metrics::counter!("strategy_bus_lag_errors_total", "channel" => "news").increment(1);
                            warn!(lagged = n, "StrategyActor lagged on raw_news");
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Closed) => {
                            error!("raw_news stream closed; exiting StrategyActor");
                            break;
                        }
                    }
                }

                // executions path
                res = executions_rx.recv() => {
                    match res {
                        Ok(executions) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "executions").increment(1);
                            if let Some(order) = self.decide_from_executions(&executions).await {
                                self.bus.orders.publish(order).await?;
                            }
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
                            metrics::counter!("strategy_bus_lag_errors_total", "channel" => "executions").increment(1);
                            warn!(lagged = n, "StrategyActor lagged on executions");
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Closed) => {
                            error!("executions stream closed; exiting StrategyActor");
                            break;
                        }
                    }
                }

                // Polymarket events path
                res = poly_rx.recv() => {
                    match res {
                        Ok(event) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "polymarket_events").increment(1);
                            if let Some(order) = self.decide_from_poly_event(&event).await {
                                self.bus.orders.publish(order).await?;
                            }
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
                             metrics::counter!("strategy_bus_lag_errors_total", "channel" => "polymarket_events").increment(1);
                            warn!(lagged = n, "StrategyActor lagged on polymarket_events");
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Closed) => {
                            error!("polymarket_events stream closed; exiting StrategyActor");
                            break;
                        }
                    }
                }

                // Balance updates
                res = balance_rx.recv() => {
                    match res {
                        Ok(update) => {
                            metrics::counter!("strategy_bus_messages_total", "channel" => "balance").increment(1);
                            info!("StrategyActor received balance update: {} USDC", update.cash);
                            self.portfolio.cash = update.cash;
                            metrics::gauge!("strategy_portfolio_cash").set(self.portfolio.cash.to_f64().unwrap_or(0.0));
                            // We wait for the next tick/poll to recalculate NLV (Equity).
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Lagged(n)) => {
                            metrics::counter!("strategy_bus_lag_errors_total", "channel" => "balance").increment(1);
                            warn!(lagged = n, "StrategyActor lagged on balance updates");
                        }
                        Err(tokio::sync::broadcast::error::RecvError::Closed) => {
                            error!("balance stream closed");
                            // Non-critical, continue
                        }
                    }
                }
            }
        }
        info!("StrategyActor stopped cleanly");
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    // use crate::config::config::CalibrationCfg;
    use crate::core::types::MarketToken;
    use crate::strategy::exact_duplicate_detector::ExactDuplicateDetectorConfig;
    use crate::strategy::sim_hash_cache::SimHashCacheConfig;
    use crate::strategy::types::{EdgedCandidate, RawCandidate, SizedDecision, TradeSide};

    #[tokio::test]
    #[ignore] // Skip test requiring Postgres connection
    async fn test_token_id_resolution() {
        // Setup minimal actor
        // Note: This test now requires a running Postgres instance.
        // Use `cargo test --ignored` if you have one running and DATABASE_URL set.
        let db_url = std::env::var("DATABASE_URL")
            .unwrap_or("postgres://user:pass@localhost:5432/db".to_string());
        let db = match crate::persistence::database::Database::new(&db_url).await {
            Ok(d) => d,
            Err(_) => return, // Skip if no DB
        };

        let mut actor = StrategyActor {
            bus: Bus::new(),
            shutdown: CancellationToken::new(),
            detector: ExactDuplicateDetector::new(ExactDuplicateDetectorConfig::default()),
            sim_hash_cache: SimHashCache::new(SimHashCacheConfig::default()),
            event_feature_extractor: EventFeatureExtractor::new(
                FeatureDictionaries::default_minimal(),
            ),
            market_index: MarketIndex::new().unwrap(),
            hard_filterer: HardFilterer::new(),
            // scorer: Scorer::new(),
            // calibrator: ProbabilityCalibrator::new(CalibrationCfg::default()),
            kelly_sizer: KellySizer::default(),
            market_data_cache: HashMap::new(),
            analyst: MarketAnalyst::new(
                LlmClient::new(crate::config::config::LlmCfg::default()),
                db.clone(),
                5,
            ),
            db,
            top_candidates: 5,
            portfolio: Portfolio::default(),
            status: crate::core::types::SystemStatus::Active,
            tokenization_config: TokenizationConfig::default(),
            market_state_cache: HashMap::new(),
            max_position_drawdown_pct: Decimal::new(20, 2), // 0.20
        };

        // Mock Market Data
        let market_id = "123456";
        let yes_token = "token_yes_123";
        let no_token = "token_no_123";

        let snap = MarketDataSnap {
            market_id: market_id.to_string(),
            book_ts_ms: 0,
            best_bid: Decimal::new(5, 1),   // 0.5
            best_ask: Decimal::new(6, 1),   // 0.6
            bid_size: Decimal::new(100, 0), // 100.0
            ask_size: Decimal::new(100, 0), // 100.0
            tokens: Some(vec![
                MarketToken {
                    token_id: yes_token.to_string(),
                    outcome: "Yes".to_string(),
                    price: Decimal::new(55, 2), // 0.55
                },
                MarketToken {
                    token_id: no_token.to_string(),
                    outcome: "No".to_string(),
                    price: Decimal::new(45, 2), // 0.45
                },
            ]),
            question: "Will the Fed hike rates?".to_string(),
        };
        actor.market_data_cache.insert(market_id.to_string(), snap);

        // Test BuyYes
        let decision_yes = SizedDecision {
            candidate: EdgedCandidate {
                candidate: RawCandidate {
                    market_id: market_id.to_string(),
                    ..Default::default()
                },
                score: Decimal::new(8, 1),         // 0.8
                probability: Decimal::new(7, 1),   // 0.7
                market_price: Decimal::new(55, 2), // 0.55
                edge: Decimal::new(15, 2),         // 0.15
            },
            kelly_fraction: Decimal::new(1, 1), // 0.1
            size_fraction: Decimal::new(1, 1),  // 0.1
            side: TradeSide::Buy("Yes".to_string()),
        };

        let orders_yes = actor
            .build_orders_from_sized_decisions(&[decision_yes], None)
            .await;
        assert_eq!(orders_yes.len(), 1);
        assert_eq!(orders_yes[0].token_id, Some(yes_token.to_string()));

        // Test BuyNo
        let decision_no = SizedDecision {
            candidate: EdgedCandidate {
                candidate: RawCandidate {
                    market_id: market_id.to_string(),
                    ..Default::default()
                },
                score: Decimal::new(8, 1),         // 0.8
                probability: Decimal::new(3, 1),   // 0.3
                market_price: Decimal::new(45, 2), // 0.45
                edge: Decimal::new(15, 2),         // 0.15
            },
            kelly_fraction: Decimal::new(1, 1), // 0.1
            size_fraction: Decimal::new(1, 1),  // 0.1
            side: TradeSide::Buy("No".to_string()),
        };

        let orders_no = actor
            .build_orders_from_sized_decisions(&[decision_no], None)
            .await;
        assert_eq!(orders_no.len(), 1);
        assert_eq!(orders_no[0].token_id, Some(no_token.to_string()));
    }

    #[tokio::test]
    #[ignore] // Requires proper DB setup or mocking of DB
    async fn test_polling_logic() {
        // This test verifies that we can compile the polling loop structure.
        // Running it requires a DB connection, which is omitted here for CI stability.
        assert!(true);
    }
}
